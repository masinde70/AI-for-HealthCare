{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306e7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Import any other stats/DL/ML packages you may need here. E.g. Keras, scikit-learn, etc.\n",
    "from itertools import chain\n",
    "import sklearn.model_selection as skl\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import binarize\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50 \n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb40f4",
   "metadata": {},
   "source": [
    "## Do some early processing of your metadata for easier model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4adf2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans found: 0 , Total Headers 112120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26140</th>\n",
       "      <td>00006860_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>6860</td>\n",
       "      <td>053Y</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110575</th>\n",
       "      <td>00030128_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30128</td>\n",
       "      <td>036Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1867</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16211</th>\n",
       "      <td>00004342_005.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>5</td>\n",
       "      <td>4342</td>\n",
       "      <td>042Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image Index Finding Labels  Follow-up #  Patient ID Patient Age  \\\n",
       "26140   00006860_000.png     No Finding            0        6860        053Y   \n",
       "110575  00030128_000.png     No Finding            0       30128        036Y   \n",
       "16211   00004342_005.png     No Finding            5        4342        042Y   \n",
       "\n",
       "       Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "26140               F            PA                 2048     2500   \n",
       "110575              M            PA                 1867     2021   \n",
       "16211               M            AP                 2500     2048   \n",
       "\n",
       "        OriginalImagePixelSpacing[x        y]  Unnamed: 11  path  \n",
       "26140                      0.171000  0.171000          NaN  None  \n",
       "110575                     0.194311  0.194311          NaN  None  \n",
       "16211                      0.168000  0.168000          NaN  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation\n",
    "## Load the NIH data to all_xray_df\n",
    "all_xray_df = pd.read_csv('Data_Entry_2017.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('/data','images*', '*', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1522ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65990</th>\n",
       "      <td>00016293_008.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>8</td>\n",
       "      <td>16293</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102754</th>\n",
       "      <td>00027408_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>27408</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99867</th>\n",
       "      <td>00026451_041.png</td>\n",
       "      <td>Effusion|Pneumothorax</td>\n",
       "      <td>41</td>\n",
       "      <td>26451</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image Index         Finding Labels  Follow-up #  Patient ID  \\\n",
       "65990   00016293_008.png             No Finding            8       16293   \n",
       "102754  00027408_000.png             No Finding            0       27408   \n",
       "99867   00026451_041.png  Effusion|Pneumothorax           41       26451   \n",
       "\n",
       "        Patient Age Patient Gender View Position  OriginalImage[Width  \\\n",
       "65990            42              M            PA                 2992   \n",
       "102754           31              M            PA                 2992   \n",
       "99867            51              M            AP                 3056   \n",
       "\n",
       "        Height]  OriginalImagePixelSpacing[x     y]  Unnamed: 11  path  \n",
       "65990      2991                        0.143  0.143          NaN  None  \n",
       "102754     2991                        0.143  0.143          NaN  None  \n",
       "99867      2544                        0.139  0.139          NaN  None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove the character in Patient Age, and convert to integer\n",
    "all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: str(x)[:-1]).astype(int)\n",
    "all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc656224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112104.000000</td>\n",
       "      <td>112104.000000</td>\n",
       "      <td>112104.000000</td>\n",
       "      <td>112104.000000</td>\n",
       "      <td>112104.000000</td>\n",
       "      <td>112104.000000</td>\n",
       "      <td>112104.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.574172</td>\n",
       "      <td>14345.720724</td>\n",
       "      <td>46.872574</td>\n",
       "      <td>2646.035253</td>\n",
       "      <td>2486.393153</td>\n",
       "      <td>0.155651</td>\n",
       "      <td>0.155651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.406734</td>\n",
       "      <td>8403.980520</td>\n",
       "      <td>16.598152</td>\n",
       "      <td>341.243771</td>\n",
       "      <td>401.270806</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>966.000000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13993.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2518.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>20673.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>2992.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>30805.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3827.000000</td>\n",
       "      <td>4715.000000</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Follow-up #     Patient ID    Patient Age  OriginalImage[Width  \\\n",
       "count  112104.000000  112104.000000  112104.000000        112104.000000   \n",
       "mean        8.574172   14345.720724      46.872574          2646.035253   \n",
       "std        15.406734    8403.980520      16.598152           341.243771   \n",
       "min         0.000000       1.000000       1.000000          1143.000000   \n",
       "25%         0.000000    7308.000000      35.000000          2500.000000   \n",
       "50%         3.000000   13993.000000      49.000000          2518.000000   \n",
       "75%        10.000000   20673.000000      59.000000          2992.000000   \n",
       "max       183.000000   30805.000000      95.000000          3827.000000   \n",
       "\n",
       "             Height]  OriginalImagePixelSpacing[x             y]  Unnamed: 11  \n",
       "count  112104.000000                112104.000000  112104.000000          0.0  \n",
       "mean     2486.393153                     0.155651       0.155651          NaN  \n",
       "std       401.270806                     0.016174       0.016174          NaN  \n",
       "min       966.000000                     0.115000       0.115000          NaN  \n",
       "25%      2048.000000                     0.143000       0.143000          NaN  \n",
       "50%      2544.000000                     0.143000       0.143000          NaN  \n",
       "75%      2991.000000                     0.168000       0.168000          NaN  \n",
       "max      4715.000000                     0.198800       0.198800          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any unreasonable ages!\n",
    "all_xray_df = all_xray_df[all_xray_df['Patient Age'] < 120]\n",
    "all_xray_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51344d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>...</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71890</th>\n",
       "      <td>00017714_010.png</td>\n",
       "      <td>Infiltration</td>\n",
       "      <td>10</td>\n",
       "      <td>17714</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>00005079_016.png</td>\n",
       "      <td>Infiltration</td>\n",
       "      <td>16</td>\n",
       "      <td>5079</td>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21316</th>\n",
       "      <td>00005683_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>1</td>\n",
       "      <td>5683</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
       "71890  00017714_010.png   Infiltration           10       17714           20   \n",
       "19157  00005079_016.png   Infiltration           16        5079           15   \n",
       "21316  00005683_001.png    Atelectasis            1        5683           53   \n",
       "\n",
       "      Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "71890              M            AP                 3056     2544   \n",
       "19157              M            PA                 2992     2991   \n",
       "21316              M            AP                 2500     2048   \n",
       "\n",
       "       OriginalImagePixelSpacing[x  ...  Emphysema  Fibrosis Hernia  \\\n",
       "71890                        0.139  ...          0         0      0   \n",
       "19157                        0.143  ...          0         0      0   \n",
       "21316                        0.171  ...          0         0      0   \n",
       "\n",
       "       Infiltration  Mass  No Finding  Nodule  Pleural_Thickening  Pneumonia  \\\n",
       "71890             1     0           0       0                   0          0   \n",
       "19157             1     0           0       0                   0          0   \n",
       "21316             0     0           0       0                   0          0   \n",
       "\n",
       "       Pneumothorax  \n",
       "71890             0  \n",
       "19157             0  \n",
       "21316             0  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here you may want to create some extra columns in your table with binary indicators of certain diseases \n",
    "## rather than working directly with the 'Finding Labels' column\n",
    "\n",
    "# Todo\n",
    "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # ignore empty labels\n",
    "        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
    "all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f654c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>...</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>pneumonia_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pneumonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x  ...  Fibrosis  Hernia Infiltration  Mass  \\\n",
       "0                        0.143  ...         0       0            0     0   \n",
       "1                        0.143  ...         0       0            0     0   \n",
       "2                        0.168  ...         0       0            0     0   \n",
       "3                        0.171  ...         0       0            0     0   \n",
       "4                        0.143  ...         0       1            0     0   \n",
       "\n",
       "   No Finding  Nodule  Pleural_Thickening  Pneumonia  Pneumothorax  \\\n",
       "0           0       0                   0          0             0   \n",
       "1           0       0                   0          0             0   \n",
       "2           0       0                   0          0             0   \n",
       "3           1       0                   0          0             0   \n",
       "4           0       0                   0          0             0   \n",
       "\n",
       "   pneumonia_class  \n",
       "0     No Pneumonia  \n",
       "1     No Pneumonia  \n",
       "2     No Pneumonia  \n",
       "3     No Pneumonia  \n",
       "4     No Pneumonia  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here we can create a new column called 'pneumonia_class' that will allow us to look at \n",
    "## images with or without pneumonia for binary classification\n",
    "\n",
    "# Todo\n",
    "all_xray_df['pneumonia_class'] = np.where(all_xray_df['Pneumonia']==1, 'Pneumonia', 'No Pneumonia')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9273af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_xray_df['Pneumonia'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b663599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(vargs):\n",
    "    \n",
    "    ## Either build your own or use a built-in library to split your original dataframe into two sets \n",
    "    ## that can be used for training and testing your model\n",
    "    ## It's important to consider here how balanced or imbalanced you want each of those sets to be\n",
    "    ## for the presence of pneumonia\n",
    "    \n",
    "    # Todo\n",
    "    ## It's important to consider here how balanced or imbalanced we want each of those sets to be\n",
    "    ## for the presence of pneumonia\n",
    "    \n",
    "    pmonia_df = all_xray_df[all_xray_df['Pneumonia'] == 1]\n",
    "    non_pmonia_df = all_xray_df[all_xray_df['Pneumonia'] == 0]\n",
    "    train_data, val_data = skl.train_test_split(pmonia_df, test_size = 0.2)\n",
    "    train_non_pmonia_data, val_non_pmonia_data = skl.train_test_split(non_pmonia_df, test_size = 0.5)\n",
    "    train_non_pmonia_data = train_non_pmonia_data.sample(train_data.shape[0])\n",
    "    train_data = pd.concat([train_data, train_non_pmonia_data])\n",
    "    non_pmonia_test_count = int((val_data.shape[0] / 1.2) * 98.8)\n",
    "    val_non_pmonia_data = val_non_pmonia_data.sample(non_pmonia_test_count)\n",
    "    val_data = pd.concat([val_data, val_non_pmonia_data])\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "train_df, valid_df = create_splits(all_xray_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a8a886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1081\n",
       "0    1081\n",
       "Name: Pneumonia, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Pneumonia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7fb2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22312\n",
       "1      271\n",
       "Name: Pneumonia, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['Pneumonia'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35037d27",
   "metadata": {},
   "source": [
    "# Now we can begin our model-building & training\n",
    "\n",
    "#### First suggestion: perform some image augmentation on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2b0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98aa69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_augmentation(train=True):\n",
    "    \n",
    "    ## recommendation here to implement a package like Keras' ImageDataGenerator\n",
    "    ## with some of the built-in augmentations \n",
    "    \n",
    "    ## keep an eye out for types of augmentation that are or are not appropriate for medical imaging data\n",
    "    ## Also keep in mind what sort of augmentation is or is not appropriate for testing vs validation data\n",
    "    \n",
    "    ## STAND-OUT SUGGESTION: implement some of your own custom augmentation that's *not*\n",
    "    ## built into something like a Keras package\n",
    "    \n",
    "    # Todo\n",
    "    my_idg = ImageDataGenerator(rescale=1. / 255.0,\n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.1, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=20, \n",
    "                              shear_range = 0.1,\n",
    "                              zoom_range=0.1)\n",
    "    \n",
    "    return my_idg\n",
    "\n",
    "\n",
    "def make_train_gen(df):\n",
    "    \n",
    "    ## Create the actual generators using the output of my_image_augmentation for your training data\n",
    "    ## Suggestion here to use the flow_from_dataframe library, e.g.:\n",
    "    \n",
    "#     train_gen = my_train_idg.flow_from_dataframe(dataframe=train_df, \n",
    "#                                          directory=None, \n",
    "#                                          x_col = ,\n",
    "#                                          y_col = ,\n",
    "#                                          class_mode = 'binary',\n",
    "#                                          target_size = , \n",
    "#                                          batch_size = \n",
    "#                                          )\n",
    "     # Todo\n",
    "    idg = my_image_augmentation()\n",
    "    train_gen = idg.flow_from_dataframe(dataframe=df, \n",
    "                                          directory=None, \n",
    "                                          x_col = 'path',\n",
    "                                          y_col = 'pneumonia_class',\n",
    "                                          class_mode = 'binary',\n",
    "                                          target_size =IMG_SIZE , \n",
    "                                          batch_size = 16 \n",
    "                                          )\n",
    "\n",
    "\n",
    "\n",
    "    return train_gen\n",
    "\n",
    "\n",
    "def make_val_gen(df):\n",
    "    \n",
    "#     val_gen = my_val_idg.flow_from_dataframe(dataframe = val_data, \n",
    "#                                              directory=None, \n",
    "#                                              x_col = ,\n",
    "#                                              y_col = ',\n",
    "#                                              class_mode = 'binary',\n",
    "#                                              target_size = , \n",
    "#                                              batch_size = ) \n",
    "    \n",
    "    # Todo\n",
    "    idg = my_image_augmentation(train=False)\n",
    "\n",
    "    val_gen = idg.flow_from_dataframe(dataframe=df, \n",
    "                                          directory=None, \n",
    "                                          x_col = 'path',\n",
    "                                          y_col = 'pneumonia_class',\n",
    "                                          class_mode = 'binary',\n",
    "                                          target_size =IMG_SIZE , \n",
    "                                          batch_size = 2000\n",
    "                                          )\n",
    "\n",
    "\n",
    "    return val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73fbe640",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All values in column x_col=path must be strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## May want to pull a single large batch of random validation data for testing after each epoch:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m \u001b[43mmake_train_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m val_gen \u001b[38;5;241m=\u001b[39m make_val_gen(valid_df)\n\u001b[1;32m      4\u001b[0m valX, valY \u001b[38;5;241m=\u001b[39m val_gen\u001b[38;5;241m.\u001b[39mnext()\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mmake_train_gen\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_train_gen\u001b[39m(df):\n\u001b[1;32m     26\u001b[0m     \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m## Create the actual generators using the output of my_image_augmentation for your training data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#                                          )\u001b[39;00m\n\u001b[1;32m     38\u001b[0m      \u001b[38;5;66;03m# Todo\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     idg \u001b[38;5;241m=\u001b[39m my_image_augmentation()\n\u001b[0;32m---> 40\u001b[0m     train_gen \u001b[38;5;241m=\u001b[39m \u001b[43midg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpneumonia_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_gen\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/keras/preprocessing/image.py:1610\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_duplicates\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1605\u001b[0m   warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1606\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1607\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1608\u001b[0m       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/keras/preprocessing/image.py:853\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_filenames:  \u001b[38;5;66;03m# check which image files are valid and keep them\u001b[39;00m\n\u001b[1;32m    855\u001b[0m   df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/keras/preprocessing/image.py:902\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# check that filenames/filepaths column values are all strings\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(df[x_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m))):\n\u001b[0;32m--> 902\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll values in column x_col=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m must be strings.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x_col))\n\u001b[1;32m    904\u001b[0m \u001b[38;5;66;03m# check labels are string if class_mode is binary or sparse\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n",
      "\u001b[0;31mTypeError\u001b[0m: All values in column x_col=path must be strings."
     ]
    }
   ],
   "source": [
    "## May want to pull a single large batch of random validation data for testing after each epoch:\n",
    "train_gen = make_train_gen(train_df)\n",
    "val_gen = make_val_gen(valid_df)\n",
    "valX, valY = val_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## May want to look at some examples of our augmented training data. \n",
    "## This is helpful for understanding the extent to which data is being manipulated prior to training, \n",
    "## and can be compared with how the raw data look prior to augmentation\n",
    "\n",
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    if c_y == 1: \n",
    "        c_ax.set_title('Pneumonia')\n",
    "    else:\n",
    "        c_ax.set_title('No Pneumonia')\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build your model: \n",
    "\n",
    "Recommendation here to use a pre-trained network downloaded from Keras for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model():\n",
    "    \n",
    "    # model = VGG16(include_top=True, weights='imagenet')\n",
    "    # transfer_layer = model.get_layer(lay_of_interest)\n",
    "    # vgg_model = Model(inputs = model.input, outputs = transfer_layer.output)\n",
    "    \n",
    "    # Todo\n",
    "    model = VGG16(include_top=True, weights='imagenet')\n",
    "    transfer_layer = model.get_layer('block5_pool')\n",
    "    vgg_model = Model(inputs = model.input, outputs = transfer_layer.output)\n",
    "    #for layer in vgg_model.layers[0:17]:\n",
    "    \n",
    "    for layer in vgg_model.layers[0:-2]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    vgg_model.summary()\n",
    "    return vgg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95dce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = load_pretrained_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ddb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "    vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_my_model():\n",
    "    \n",
    "    # my_model = Sequential()\n",
    "    # ....add your pre-trained model, and then whatever additional layers you think you might\n",
    "    # want for fine-tuning (Flatteen, Dense, Dropout, etc.)\n",
    "    \n",
    "    # if you want to compile your model within this function, consider which layers of your pre-trained model, \n",
    "    # you want to freeze before you compile \n",
    "    \n",
    "    # also make sure you set your optimizer, loss function, and metrics to monitor\n",
    "    \n",
    "    # Todo\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(load_pretrained_model())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer = Adam(lr=1e-4), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    \n",
    "  \n",
    "    return model\n",
    "my_model = build_my_model()\n",
    "\n",
    "## STAND-OUT Suggestion: choose another output layer besides just the last classification layer of your modele\n",
    "## to output class activation maps to aid in clinical interpretation of your model's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below is some helper code that will allow you to add checkpoints to your model,\n",
    "## This will save the 'best' version of your model by comparing it to previous epochs of training\n",
    "\n",
    "## Note that you need to choose which metric to monitor for your model's 'best' performance if using this code. \n",
    "## The 'patience' parameter is set to 10, meaning that your model will train for ten epochs without seeing\n",
    "## improvement before quitting\n",
    "\n",
    "# Todo\n",
    "\n",
    "# weight_path=\"{}_my_model.best.hdf5\".format('xray_class')\n",
    "\n",
    "# checkpoint = ModelCheckpoint(weight_path, \n",
    "#                              monitor= CHOOSE_METRIC_TO_MONITOR_FOR_PERFORMANCE, \n",
    "#                              verbose=1, \n",
    "#                              save_best_only=True, \n",
    "#                              mode= CHOOSE_MIN_OR_MAX_FOR_YOUR_METRIC, \n",
    "#                              save_weights_only = True)\n",
    "\n",
    "# early = EarlyStopping(monitor= SAME_AS_METRIC_CHOSEN_ABOVE, \n",
    "#                       mode= CHOOSE_MIN_OR_MAX_FOR_YOUR_METRIC, \n",
    "#                       patience=10)\n",
    "\n",
    "# callbacks_list = [checkpoint, early]\n",
    "weight_path=\"{}_my_model.best.hdf5\".format('xray_class')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, \n",
    "                              monitor='val_loss', \n",
    "                              verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              mode='min', \n",
    "                              save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', \n",
    "                       mode='min', \n",
    "                       patience=10)\n",
    "\n",
    "callbacks_list = [checkpoint, early]\n",
    "print(weight_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a95c2",
   "metadata": {},
   "source": [
    "### Start training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train your model\n",
    "\n",
    "# Todo\n",
    "\n",
    "# history = my_model.fit_generator(train_gen, \n",
    "#                           validation_data = (valX, valY), \n",
    "#                           epochs = , \n",
    "#                           callbacks = callbacks_list)\n",
    "history = my_model.fit_generator(train_gen, \n",
    "                           validation_data = (valX, valY), \n",
    "                           epochs = 15, \n",
    "                           callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3a04a",
   "metadata": {},
   "source": [
    "##### After training for some time, look at the performance of your model by plotting some performance statistics:\n",
    "\n",
    "Note, these figures will come in handy for your FDA documentation later in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After training, make some predictions to assess your model's overall performance\n",
    "## Note that detecting pneumonia is hard even for trained expert radiologists, \n",
    "## so there is no need to make the model perfect.\n",
    "my_model.load_weights(weight_path)\n",
    "pred_Y = my_model.predict(valX, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot figures\n",
    "plt.hist(pred_Y, bins=25, color='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
